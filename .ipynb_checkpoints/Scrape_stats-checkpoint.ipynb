{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Letters to iterate through\n",
    "alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'y', 'z']\n",
    "#Empty lists to store our data\n",
    "names_list = []\n",
    "links_list = []\n",
    "start_list = []\n",
    "end_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Link</th>\n",
       "      <th>StartYear</th>\n",
       "      <th>EndYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alaa Abdelnaby</td>\n",
       "      <td>/players/a/abdelal01.html</td>\n",
       "      <td>1991</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zaid Abdul-Aziz</td>\n",
       "      <td>/players/a/abdulza01.html</td>\n",
       "      <td>1969</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kareem Abdul-Jabbar</td>\n",
       "      <td>/players/a/abdulka01.html</td>\n",
       "      <td>1970</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mahmoud Abdul-Rauf</td>\n",
       "      <td>/players/a/abdulma02.html</td>\n",
       "      <td>1991</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tariq Abdul-Wahad</td>\n",
       "      <td>/players/a/abdulta01.html</td>\n",
       "      <td>1998</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>Ante Žižić</td>\n",
       "      <td>/players/z/zizican01.html</td>\n",
       "      <td>2018</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>Jim Zoet</td>\n",
       "      <td>/players/z/zoetji01.html</td>\n",
       "      <td>1983</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>Bill Zopf</td>\n",
       "      <td>/players/z/zopfbi01.html</td>\n",
       "      <td>1971</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>Ivica Zubac</td>\n",
       "      <td>/players/z/zubaciv01.html</td>\n",
       "      <td>2017</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>Matt Zunic</td>\n",
       "      <td>/players/z/zunicma01.html</td>\n",
       "      <td>1949</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Player                       Link StartYear EndYear\n",
       "0          Alaa Abdelnaby  /players/a/abdelal01.html      1991    1995\n",
       "1         Zaid Abdul-Aziz  /players/a/abdulza01.html      1969    1978\n",
       "2     Kareem Abdul-Jabbar  /players/a/abdulka01.html      1970    1989\n",
       "3      Mahmoud Abdul-Rauf  /players/a/abdulma02.html      1991    2001\n",
       "4       Tariq Abdul-Wahad  /players/a/abdulta01.html      1998    2003\n",
       "...                   ...                        ...       ...     ...\n",
       "4795           Ante Žižić  /players/z/zizican01.html      2018    2020\n",
       "4796             Jim Zoet   /players/z/zoetji01.html      1983    1983\n",
       "4797            Bill Zopf   /players/z/zopfbi01.html      1971    1971\n",
       "4798          Ivica Zubac  /players/z/zubaciv01.html      2017    2020\n",
       "4799           Matt Zunic  /players/z/zunicma01.html      1949    1949\n",
       "\n",
       "[4800 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for letter in alphabet:\n",
    "    #Link to webpage using requests and BeautifulSoup\n",
    "    page = requests.get('https://www.basketball-reference.com/players/' + letter)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    #Select The table then the rows\n",
    "    table = soup.find('table', class_ = 'sortable stats_table')\n",
    "    rows = table.findAll('tr')\n",
    "    \n",
    "    #Iterate through the rows and get all player names\n",
    "    new_names_list = [row.find('th') for row in rows]\n",
    "    new_names_list = [name.find('a') for name in new_names_list]\n",
    "    new_names_list = [name for name in new_names_list if name]\n",
    "    new_names_list = [name.string for name in new_names_list]\n",
    "    \n",
    "    #Iterate through the rows and get links to all player pages\n",
    "    new_links_list = [row.find('th') for row in rows]\n",
    "    new_links_list = [link.find('a') for link in new_links_list]\n",
    "    new_links_list = [link for link in new_links_list if link]\n",
    "    new_links_list = [link['href'] for link in new_links_list]\n",
    "    \n",
    "    #Iterate and get first year of a players career\n",
    "    new_start_list = [row.findAll('td') for row in rows]\n",
    "    new_start_list = [year for year in new_start_list if year]\n",
    "    new_start_list = [year[0].string for year in new_start_list]\n",
    "    \n",
    "    #Iterate and get last year\n",
    "    new_end_list = [row.findAll('td') for row in rows]\n",
    "    new_end_list = [year for year in new_end_list if year]\n",
    "    new_end_list = [year[1].string for year in new_end_list]\n",
    "    \n",
    "    #Add the new data to our lists\n",
    "    names_list = names_list + new_names_list\n",
    "    links_list = links_list + new_links_list\n",
    "    start_list = start_list + new_start_list\n",
    "    end_list = end_list + new_end_list\n",
    "\n",
    "#Turn our lists into a dataframe and name the columns    \n",
    "df = pd.DataFrame([names_list, links_list, start_list, end_list]).transpose()\n",
    "df.columns = ['Player', 'Link', 'StartYear', 'EndYear']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change data types of years to int64 and creating a column for amount of time in league\n",
    "df.StartYear = df.StartYear.astype('int64')\n",
    "df.EndYear = df.EndYear.astype('int64')\n",
    "df['Tenure'] = df.EndYear - df.StartYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eligible = df[(df.EndYear <= 2016) & (df.Tenure > 4)]\n",
    "df_eligible.reset_index(inplace = True)\n",
    "#Limiting our data to players who retired in 2016 or earlier so that all players are hall of fame eligible\n",
    "#Also removed any player who didn't last more than 4 seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_player_info(href1):\n",
    "    page = requests.get('https://www.basketball-reference.com'+str(href1))\n",
    "    #Name of Player\n",
    "    #soup = BS(page.content, 'html.parser')\n",
    "    #table_body=soup.find_all(itemprop= \"name\")\n",
    "    #table_body\n",
    "    #name= re.findall('<h1 itemprop=\\\"name\\\">(.*)</h1>', str(table_body))\n",
    "    #if len(name)==0:\n",
    "    #    name= re.findall('<span>(.*)</span>', str(table_body))\n",
    "    #else:\n",
    "    #    pass\n",
    "    \n",
    "    #Bio\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    table_body=soup.find_all('p')\n",
    "    work=table_body[0:10]\n",
    "    #print(work)\n",
    "    height= re.findall('(\\d*cm)', str(work))\n",
    "    weight= re.findall('(\\d*kg)', str(work))\n",
    "    bday= re.findall('data-birth=\\\"(\\d*\\-\\d*\\-\\d*)', str(work))\n",
    "    #accolades\n",
    "    accolades_body=soup.find(id=\"bling\")\n",
    "    All_Star_apps= re.findall('(\\d*)x All Star', str(accolades_body))\n",
    "    All_NBA_apps= re.findall('(\\d*)x All-NBA', str(accolades_body))\n",
    "    All_Def_apps= re.findall('(\\d*)x All-Defensive', str(accolades_body))\n",
    "    HOF= re.findall('(Hall of Fame)', str(accolades_body))\n",
    "    empty_list=0\n",
    "    if len(All_Star_apps)==empty_list:\n",
    "        All_Star_apps='0'\n",
    "    else:\n",
    "        All_Star_apps=All_Star_apps[0]\n",
    "    if len(All_NBA_apps)==empty_list:\n",
    "        All_NBA_apps='0'\n",
    "    else:\n",
    "        All_NBA_apps=All_NBA_apps[0]\n",
    "    if len(All_Def_apps)==empty_list:\n",
    "        All_Def_apps='0'\n",
    "    else:\n",
    "        All_Def_apps= All_Def_apps[0]\n",
    "    if len(HOF)==empty_list:\n",
    "        HOF='0'\n",
    "    else:\n",
    "        HOF= HOF[0]\n",
    "    bio= [height[0],weight[0],bday[0],All_Star_apps,All_NBA_apps,All_Def_apps,HOF]\n",
    "    \n",
    "    #Find Stats overview, then pull out individual stats then extract the stats and make them a list\n",
    "    stats = soup.find('div', class_ = \"stats_pullout\")\n",
    "    cells = stats.find_all('p')\n",
    "    stats_list = list(map(lambda x : x.string, cells[3:23:2]))\n",
    "    \n",
    "    return bio + stats_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_list = [get_player_info(link) for link in df_eligible.Link]\n",
    "#Very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.DataFrame(info_list, columns=['Height','Weight','Birthday','All_Star_apps','All_NBA_apps','All_Def_apps','HOF', 'Games', 'PPG', 'TRPG', 'APG', 'FG_pct', '3_pt_pct', 'FT_pct', 'eFG_pct', 'PER', 'WS'])\n",
    "df_eligible = pd.concat([df_eligible, df_info], axis = 1)\n",
    "df_eligible\n",
    "#Concat the data about the players from info_list and the list of players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458, 23)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eligible.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.basketball-reference.com/players/a/abdulka01.html\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = soup.find('div', class_ = \"stats_pullout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = stats.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p><strong></strong></p>,\n",
       " <p><strong>Career</strong></p>,\n",
       " <p></p>,\n",
       " <p>1560</p>,\n",
       " <p></p>,\n",
       " <p>24.6</p>,\n",
       " <p></p>,\n",
       " <p>11.2</p>,\n",
       " <p></p>,\n",
       " <p>3.6</p>,\n",
       " <p></p>,\n",
       " <p>55.9</p>,\n",
       " <p></p>,\n",
       " <p>5.6</p>,\n",
       " <p></p>,\n",
       " <p>72.1</p>,\n",
       " <p></p>,\n",
       " <p>55.9</p>,\n",
       " <p></p>,\n",
       " <p>24.6</p>,\n",
       " <p></p>,\n",
       " <p>273.4</p>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1560', '24.6', '11.2', '3.6', '55.9', '5.6', '72.1', '55.9', '24.6', '273.4']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x : x.string, cells[3:23:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1560'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells[3].string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_world_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6c4ee20ac618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_world_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Player'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdata_world_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Player'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_world_set' is not defined"
     ]
    }
   ],
   "source": [
    "data_world_set['Player']= data_world_set['Player'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
