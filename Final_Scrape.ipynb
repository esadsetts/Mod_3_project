{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Letters to iterate through\n",
    "alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'y', 'z']\n",
    "#Empty lists to store our data\n",
    "names_list = []\n",
    "links_list = []\n",
    "start_list = []\n",
    "end_list = []\n",
    "pos_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in alphabet:\n",
    "    #Link to webpage using requests and BeautifulSoup\n",
    "    page = requests.get('https://www.basketball-reference.com/players/' + letter)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    #Select The table then the rows\n",
    "    table = soup.find('table', class_ = 'sortable stats_table')\n",
    "    rows = table.findAll('tr')\n",
    "    \n",
    "    #Iterate through the rows and get all player names\n",
    "    new_names_list = [row.find('th') for row in rows]\n",
    "    new_names_list = [name.find('a') for name in new_names_list]\n",
    "    new_names_list = [name for name in new_names_list if name]\n",
    "    new_names_list = [name.string for name in new_names_list]\n",
    "    \n",
    "    #Iterate through the rows and get links to all player pages\n",
    "    new_links_list = [row.find('th') for row in rows]\n",
    "    new_links_list = [link.find('a') for link in new_links_list]\n",
    "    new_links_list = [link for link in new_links_list if link]\n",
    "    new_links_list = [link['href'] for link in new_links_list]\n",
    "    \n",
    "    #Iterate and get first year of a players career\n",
    "    new_start_list = [row.findAll('td') for row in rows]\n",
    "    new_start_list = [year for year in new_start_list if year]\n",
    "    new_start_list = [year[0].string for year in new_start_list]\n",
    "    \n",
    "    #Iterate and get last year\n",
    "    new_end_list = [row.findAll('td') for row in rows]\n",
    "    new_end_list = [year for year in new_end_list if year]\n",
    "    new_end_list = [year[1].string for year in new_end_list]\n",
    "    \n",
    "    #Iterate and get position\n",
    "    new_pos_list = [row.findAll('td') for row in rows]\n",
    "    new_pos_list = [pos for pos in new_pos_list if pos]\n",
    "    new_pos_list = [pos[2].string.replace('-','') for pos in new_pos_list]\n",
    "    \n",
    "    #Add the new data to our lists\n",
    "    names_list = names_list + new_names_list\n",
    "    links_list = links_list + new_links_list\n",
    "    start_list = start_list + new_start_list\n",
    "    end_list = end_list + new_end_list\n",
    "    pos_list = pos_list + new_pos_list\n",
    "    \n",
    "    \n",
    "#Turn our lists into a dataframe and name the columns    \n",
    "df = pd.DataFrame([names_list, links_list, start_list, end_list, pos_list]).transpose()\n",
    "df.columns = ['Player', 'Link', 'StartYear', 'EndYear', 'Position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change data types of years to int64 and creating a column for amount of time in league\n",
    "df.StartYear = df.StartYear.astype('int64')\n",
    "df.EndYear = df.EndYear.astype('int64')\n",
    "df['Tenure'] = df.EndYear - df.StartYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eligible = df[(df.EndYear <= 2016) & (df.Tenure > 4)]\n",
    "df_eligible.reset_index(inplace = True, drop = True)\n",
    "#Limiting our data to players who retired in 2016 or earlier so that all players are hall of fame eligible\n",
    "#Also removed any player who didn't last more than 4 seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_info(href1):\n",
    "    page = requests.get('https://www.basketball-reference.com'+str(href1))\n",
    "    #Name of Player\n",
    "    #soup = BS(page.content, 'html.parser')\n",
    "    #table_body=soup.find_all(itemprop= \"name\")\n",
    "    #table_body\n",
    "    #name= re.findall('<h1 itemprop=\\\"name\\\">(.*)</h1>', str(table_body))\n",
    "    #if len(name)==0:\n",
    "    #    name= re.findall('<span>(.*)</span>', str(table_body))\n",
    "    #else:\n",
    "    #    pass\n",
    "    \n",
    "    #Bio\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    table_body=soup.find_all('p')\n",
    "    work=table_body[0:10]\n",
    "    #print(work)\n",
    "    height= re.findall('(\\d*cm)', str(work))\n",
    "    weight= re.findall('(\\d*kg)', str(work))\n",
    "    bday= re.findall('data-birth=\\\"(\\d*\\-\\d*\\-\\d*)', str(work))\n",
    "    #accolades\n",
    "    accolades_body=soup.find(id=\"bling\")\n",
    "    All_Star_apps= re.findall('(\\d*)x All Star', str(accolades_body))\n",
    "    All_NBA_apps= re.findall('(\\d*)x All-NBA', str(accolades_body))\n",
    "    All_Def_apps= re.findall('(\\d*)x All-Defensive', str(accolades_body))\n",
    "    HOF= re.findall('(Hall of Fame)', str(accolades_body))\n",
    "    empty_list=0\n",
    "    if len(All_Star_apps)==empty_list:\n",
    "        All_Star_apps='0'\n",
    "    else:\n",
    "        All_Star_apps=All_Star_apps[0]\n",
    "    if len(All_NBA_apps)==empty_list:\n",
    "        All_NBA_apps='0'\n",
    "    else:\n",
    "        All_NBA_apps=All_NBA_apps[0]\n",
    "    if len(All_Def_apps)==empty_list:\n",
    "        All_Def_apps='0'\n",
    "    else:\n",
    "        All_Def_apps= All_Def_apps[0]\n",
    "    if len(HOF)==empty_list:\n",
    "        HOF='0'\n",
    "    else:\n",
    "        HOF= HOF[0]\n",
    "    bio= [height[0],weight[0],bday[0],All_Star_apps,All_NBA_apps,All_Def_apps,HOF]\n",
    "    \n",
    "    #Find Stats overview, then pull out individual stats then extract the stats and make them a list\n",
    "    stats = soup.find('div', class_ = \"stats_pullout\")\n",
    "    cells = stats.find_all('p')\n",
    "    stats_list = list(map(lambda x : x.string, cells[3:23:2]))\n",
    "    \n",
    "    return bio + stats_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_list = [get_player_info(link) for link in df_eligible.Link]\n",
    "#Very Slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.DataFrame(info_list, columns=['Height','Weight','Birthday','All_Star_apps','All_NBA_apps','All_Def_apps','HOF', 'Games', 'PPG', 'TRPG', 'APG', 'FG_pct', '3_pt_pct', 'FT_pct', 'eFG_pct', 'PER', 'WS'])\n",
    "df_eligible = pd.concat([df_eligible, df_info], axis = 1)\n",
    "#Add new columns to our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eligible.to_csv('bbal_scraped_data.csv')\n",
    "#export dataframe to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
